Christmas Story Generator ğŸ„
============================

Christmas Story Generator is a Streamlit web app built for the **Datapizza AI Christmas Challenge**. It creates short, cozy Christmas stories for kids and generates one illustration per scene using **Groq + Datapizza AI** for text and **PyTorch + diffusers (SDXL)** for images.

The goal is to explore an endâ€‘toâ€‘end storybook pipeline: prompt engineering for safe, kidâ€‘friendly stories, automatic scene splitting, imageâ€‘prompt generation, and a simple web UI for running everything locally.

***

## Tech stack

- Frontend / UI: Streamlit.
- LLM client: Datapizza OpenAI-style client (Groq backend).
- Image generation: PyTorch + `diffusers` with Stable Diffusion XL base 1.0.
- PDF / images: Pillow, ReportLab.
- Environment: Python 3.10-3.12 in a dedicated virtual environment (avoid 3.13 for now due a libs support).

***

## Features

- Input:
  - Child name and age.
  - Themes / keywords, with a button to sample 3 random themes from a predefined pool.
- Story generation:
  - A Datapizza `Agent` writes a short Christmas story split into scenes, each ending with `[SCENE_BREAK]`.
  - A safety tool sanitizes edgy keywords into kidâ€‘friendly Christmas concepts (e.g. â€œgunâ€ â†’ â€œsnowball blasterâ€).
- Character description:
  - A second `Agent` generates a single, detailed visual description of the main character, optimized for inclusion in SDXL prompts.
- Image generation:
  - For each scene, a Stable Diffusion prompt is created by combining the scene text, the character description, and a fixed â€œstorybookâ€ style preset.
  - SDXL renders one illustration per scene.
- UI / UX:
  - Main page: Story settings, character description, full story, and a responsive HTML grid of all illustrated scenes.
  - History page: Browse previous storybooks, reload their text and images, and view them with the same HTML layout.

***

## Project structure

```text
.
â”œâ”€ app.py                 # Streamlit UI entrypoint
â”œâ”€ core/
â”‚   â”œâ”€ __init__.py        # Re-exports build_clients, build_pipeline, generate_storybook
â”‚   â”œâ”€ config.py          # Constants: OUT_DIR, STEPS, WIDTH/HEIGHT, STYLE_PRESET, NEGATIVE, THEME_POOL
â”‚   â”œâ”€ clients.py         # Datapizza / Groq Agents, sanitize_keywords tool
â”‚   â”œâ”€ pipeline.py        # SDXL pipeline construction (GPU/CPU)
â”‚   â”œâ”€ story.py           # Story, character description, image-prompt generation
â”‚   â”œâ”€ images.py          # generate_ai_illustration using SDXL
â”‚   â”œâ”€ export.py          # PDF export (ReportLab)
â”‚   â””â”€ storybook.py       # Orchestrator: generate_storybook, save PNGs + story.json + PDF
â”œâ”€ pages/
â”‚   â””â”€ 01_Stories_history.py  # Streamlit multipage: browse past stories
â”œâ”€ outputs/
â”‚   â””â”€ <story_id>/
â”‚       â”œâ”€ 01.png, 02.png, ...
â”‚       â”œâ”€ story.json
â”‚       â””â”€ <ild>_christmas_storybook.pdf
â”œâ”€ requirements.txt       # Python dependencies
â””â”€ README.md              # This file
```

Each story is fully selfâ€‘contained in `outputs/<story_id>/`, including all images, metadata (`story.json`), and the exported PDF.

***

## Requirements

- Python: 3.10.x-3.12.x (recommended for PyTorch + diffusers).
- OS: developed on Windows; should work similarly on Linux/macOS with the same Python version.
- Hardware:
  - GPU (CUDA) strongly recommended for SDXL (large model, faster inference).
  - CPUâ€‘only works but is slower; you may want to reduce:
    - `STEPS` (e.g. ~12â€“20).
    - `WIDTH` / `HEIGHT` (e.g. 512Ã—512 or smaller).

---

## Installation & setup (Windows / PowerShell)

1. **Clone the repository**

```powershell
git clone https://github.com/tommasofacchin/christmas-story-generator.git
cd christmas-story-generator

# Create a virtual environment (Python 3.10â€“3.12)
py -3.12 -m venv .venv

# Activate the venv
.\.venv\Scripts\Activate.ps1

python --version  # should show 3.10â€“3.12

# Install dependencies
python -m pip install --upgrade pip
pip install -r requirements.txt

# Run the app
streamlit run app.py

# Deactivate when finished
deactivate
```

---

## Configuration: API keys and tokens

### GROQ API key (required)

The app uses a Datapizza client that talks to the **Groq** OpenAIâ€‘compatible API.

- Start the app with `streamlit run app.py`.
- In the **sidebar**, paste your **GROQ API key** into the `GROQ API key` field.
- The key is only used at runtime and is not committed to the repo.

Each user can provide their own key when running the app locally or on their own deployment.

### Hugging Face token (optional)

- Used to authenticate, if needed, when downloading **Stable Diffusion XL base 1.0** from Hugging Face.
- If you donâ€™t have a token or the model is accessible anonymously, you can leave this empty.

***

## SDXL pipeline: CPU vs GPU

In `core/pipeline.py`, the SDXL pipeline is built with a simple device check:

- If `torch.cuda.is_available()` is `True`, SDXL loads on **GPU** with half precision (`torch.float16`).
- Otherwise, it falls back to **CPU** in full precision (`torch.float32`).

On CPU you might want to tune parameters in `core/config.py`:

- `STEPS`: reduce for faster generation (e.g. 12â€“20).
- `WIDTH` / `HEIGHT`: smaller resolutions to fit memory and speed requirements.
- Optionally, fewer scenes (`MIN_SCENES`, `MAX_SCENES`) for lighter runs.

***

## How it works (high level)

1. The user fills in child name, age, and themes (or clicks the ğŸ² button to sample 3 random themes from `THEME_POOL`).  
2. `build_clients` creates two Datapizza Agents:
   - Story agent (writes the story with `[SCENE_BREAK]` separators).
   - Prompt agent (writes SDXLâ€‘friendly visual/scene prompts).
3. `generate_storybook`:
   - Sanitizes keywords.
   - Generates the full story and splits it into scenes.
   - Generates a character description.
   - For each scene, generates a diffusion prompt and calls the SDXL pipeline to render an image.
   - Saves images and metadata under `outputs/<story_id>/`.
4. `app.py`:
   - Shows story info, character, and full story.
   - Renders all scenes in a responsive HTML grid (both for the live run and in the history page).
